{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | LastName, FirstName\n",
        "**Section** | CPE31Sx\n",
        "**Date Performed**: |\n",
        "**Date Submitted**: |\n",
        "**Instructor**: | Dr. Jonathan V. Taylar / Engr. Verlyn V. Nojor / Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to enable students to perform data preparation and face recognition on their own generated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Utilize data preparation techniques for images.\n",
        "* Perform Face Recognition using multiple algorithms.\n",
        "* Evaluate the performance of different algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBQh8Eyf1EHC"
      },
      "source": [
        "### Preparing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpAAiS_V1Jfy"
      },
      "source": [
        "Now that we have our data, we need to load these sample pictures into our face recognition algorithms. All face recognition algorithms take two parameters in their `train()` method: an array of images and an array of labels. What do these labels represent? They are the IDs of a certain individual/face so that when face recognition is performed, we not only know the person was recognized but also who—among the many people available in our database—the person is.\n",
        "\n",
        "To do that, we need to create a comma-separated value (CSV) file, which will contain the path to a sample picture followed by the ID of that person."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWqIq9Sz1Svi"
      },
      "source": [
        "**Include a Screenshot of Your Dataset Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SiR2yJQ1W7B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPA3SGHN1YdC"
      },
      "source": [
        "### Loading the data and recognizing faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q07mfdMq1b2J"
      },
      "source": [
        "Next up, we need to load these two resources (the array of images and CSV file) into the face recognition algorithm, so it can be trained to recognize our face. To do this, we build a function that reads the CSV file and—for each line of the file—loads the image at the corresponding path into the images array and the ID into the labels array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 40 images with 2 unique labels.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def read_images(path, sz=None):\n",
        "    if not os.path.exists(path): \n",
        "        return None, None  \n",
        "\n",
        "    c = 0\n",
        "    X, y = [], []\n",
        "\n",
        "    for dirname, dirnames, filenames in os.walk(path):\n",
        "        for subdirname in dirnames:\n",
        "            subject_path = os.path.join(dirname, subdirname)\n",
        "            for filename in os.listdir(subject_path):\n",
        "                if filename.startswith('.'):  \n",
        "                    continue\n",
        "\n",
        "                filepath = os.path.join(subject_path, filename)\n",
        "                im = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if im is None:  \n",
        "                    continue\n",
        "\n",
        "                if sz is not None:\n",
        "                    im = cv2.resize(im, (200, 200))\n",
        "\n",
        "                X.append(np.asarray(im, dtype=np.uint8))\n",
        "                y.append(c)\n",
        "\n",
        "            c += 1  \n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "dataset_path = r\"C:\\Users\\blizz\\Downloads\\faceset\"\n",
        "X, y = read_images(dataset_path, sz=(200, 200))\n",
        "\n",
        "if X is not None and y is not None:\n",
        "    print(f\"Loaded {len(X)} images with {len(set(y))} unique labels.\")\n",
        "else:\n",
        "    print(\"Dataset not found or empty.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWNBxCbO2oO-"
      },
      "source": [
        "**Question: Run the function above on your generated dataset. Provide an analysis and note all the challenges you have encountered running this code.**\n",
        "\n",
        "it doesn't filter out non-image files and doesn't have a label dictionary which also leads to errors, storing all in just numpy array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5IMZcC3wZt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlLWfyvY3xm0"
      },
      "source": [
        "### Performing Face Recognition Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVF9dfTQ30pc"
      },
      "source": [
        "Here is a sample script for testing the Face Recognition Algorithm. In this section, we're going to follow the same process but with different algorithms for face recognitions, namely:\n",
        "- Eigenface Recognition\n",
        "- Fisherface Recognition\n",
        "- Local Binary Pattern Histograms (LBPH) Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Load Haar cascade\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# Paths\n",
        "MODEL_PATH = \"face_model.yml\"\n",
        "LABEL_DICT_PATH = \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "\n",
        "def face_rec():\n",
        "    names = np.load(LABEL_DICT_PATH, allow_pickle=True).item()  # Load label dictionary\n",
        "\n",
        "    # Load the trained model\n",
        "    model = cv2.face.EigenFaceRecognizer_create()\n",
        "    model.read(MODEL_PATH)  # Load pre-trained model\n",
        "\n",
        "    camera = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        ret, img = camera.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(40, 40))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            try:\n",
        "                label_id, confidence = model.predict(roi)\n",
        "                label = names.get(label_id, \"Unknown\")  # Get name from dictionary\n",
        "                cv2.putText(img, f\"{label}, {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    camera.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    face_rec()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading images and training the model...\n",
            "Training complete! Model saved as 'face_model.yml'. Label dictionary saved as 'label_dictionary.npy'.\n",
            "Label dictionary: {0: 'dad', 1: 'john'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Load Haar cascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# Paths\n",
        "DATASET_PATH = \"faceset/\"\n",
        "MODEL_PATH = \"face_model.yml\"\n",
        "LABEL_DICT_PATH = \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "\n",
        "def read_images(path):\n",
        "    \"\"\" Reads images, detects faces, and prepares training data. \"\"\"\n",
        "    X, y = [], []\n",
        "    label_dict = {}\n",
        "    label_id = 0  \n",
        "\n",
        "    for subdirname in sorted(os.listdir(path)):\n",
        "        subject_path = os.path.join(path, subdirname)\n",
        "        if not os.path.isdir(subject_path):\n",
        "            continue  \n",
        "\n",
        "        label_dict[label_id] = subdirname  \n",
        "\n",
        "        for filename in sorted(os.listdir(subject_path)):\n",
        "            filepath = os.path.join(subject_path, filename)\n",
        "            img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Skipping {filename}: Invalid image\")\n",
        "                continue  \n",
        "\n",
        "            # Preprocess image (Histogram Equalization for better contrast)\n",
        "            img = cv2.equalizeHist(img)\n",
        "\n",
        "            faces = face_cascade.detectMultiScale(img, scaleFactor=1.2, minNeighbors=6, minSize=(40, 40))\n",
        "            if len(faces) == 0:\n",
        "                print(f\"Skipping {filename}: No face detected\")\n",
        "                continue  \n",
        "\n",
        "            for (x, y_, w, h) in faces:\n",
        "                face = img[y_:y_ + h, x:x + w]\n",
        "                face = cv2.resize(face, IMAGE_SIZE)  \n",
        "\n",
        "                X.append(face)\n",
        "                y.append(label_id)\n",
        "                break  \n",
        "\n",
        "        label_id += 1\n",
        "\n",
        "    return X, y, label_dict\n",
        "\n",
        "# Read images and extract faces\n",
        "print(\"Reading images and training the model...\")\n",
        "X, y, label_dict = read_images(DATASET_PATH)\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    print(\"Error: No faces found. Check your dataset.\")\n",
        "    exit()\n",
        "\n",
        "X = np.array(X, dtype=np.uint8)\n",
        "y = np.array(y, dtype=np.int32)\n",
        "\n",
        "# Create and train EigenFace recognizer\n",
        "recognizer = cv2.face.EigenFaceRecognizer_create()\n",
        "recognizer.train(X, y)\n",
        "\n",
        "# Save trained model and labels\n",
        "recognizer.save(MODEL_PATH)\n",
        "np.save(LABEL_DICT_PATH, label_dict)\n",
        "\n",
        "print(f\"Training complete! Model saved as '{MODEL_PATH}'. Label dictionary saved as '{LABEL_DICT_PATH}'.\")\n",
        "print(\"Label dictionary:\", label_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "cYQ19foI4Oe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 'q' to quit.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"eigen_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "CONFIDENCE_THRESHOLD = 6000\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            for (x, y_, w, h) in faces:\n",
        "                X.append(cv2.resize(img[y_:y_ + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id)\n",
        "    if not X: raise ValueError(\"No faces detected.\")\n",
        "    return np.array(X, np.uint8), np.array(y, np.int32), labels\n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.EigenFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return print(\"Camera error.\")\n",
        "    print(\"Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            text = labels.get(label, \"Unknown\") if conf < CONFIDENCE_THRESHOLD else \"Unknown\"\n",
        "            cv2.putText(img, f\"{text}, {conf:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        model, labels = train_model()\n",
        "        recognize_faces(model, labels)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iChhyN_Y4OH7"
      },
      "source": [
        "**Question: Provide an analysis of the sample script for the process using the Eigenface Model. What is the sample code doing? Are you able to troubleshoot any problems encountered?**\n",
        "\n",
        "The script implements an Eigenface-based face recognition system using OpenCV, following three main steps: data preparation, model training, and real-time recognition. It reads images, detects faces using Haar cascade, resizes them, and assigns labels before training an EigenFaceRecognizer model. During real-time recognition, the webcam captures faces, predicts identities, and labels them based on confidence scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dL7n-mc5JO6"
      },
      "source": [
        "---\n",
        "Perform the remaining face recognition techniques by using the same (or modified) process from the sample code:\n",
        "\n",
        "- `model = cv2.face.createFisherFaceRecognizer()`\n",
        "- `model = cv2.face.createLBPHFaceRecognizer()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading images and training...\n",
            "Model saved as 'fisher_face_model.yml', Labels saved as 'label_dictionary.npy' {0: 'dad', 1: 'john'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "DATASET_PATH, FISHER_MODEL_PATH, LABEL_DICT_PATH = \"faceset/\", \"fisher_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, label_dict = [], [], {}\n",
        "    for label_id, subdirname in enumerate(sorted(os.listdir(path))):\n",
        "        subject_path = os.path.join(path, subdirname)\n",
        "        if not os.path.isdir(subject_path): continue\n",
        "        label_dict[label_id] = subdirname  \n",
        "        for filename in sorted(os.listdir(subject_path)):\n",
        "            img = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            img = cv2.equalizeHist(img)\n",
        "            faces = face_cascade.detectMultiScale(img, 1.2, 6, minSize=(40, 40))\n",
        "            if len(faces) == 0: continue\n",
        "            X.append(cv2.resize(img[faces[0][1]:faces[0][1] + faces[0][3], faces[0][0]:faces[0][0] + faces[0][2]], IMAGE_SIZE))\n",
        "            y.append(label_id)\n",
        "    return np.array(X, np.uint8), np.array(y, np.int32), label_dict\n",
        "\n",
        "print(\"Reading images and training...\")\n",
        "X, y, label_dict = read_images(DATASET_PATH)\n",
        "if X.size == 0: exit(\"Error: No faces found.\")\n",
        "\n",
        "recognizer = cv2.face.FisherFaceRecognizer_create()\n",
        "recognizer.train(X, y)\n",
        "recognizer.save(FISHER_MODEL_PATH)\n",
        "np.save(LABEL_DICT_PATH, label_dict)\n",
        "print(f\"Model saved as '{FISHER_MODEL_PATH}', Labels saved as '{LABEL_DICT_PATH}'\", label_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 'q' to quit.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"fisher_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "CONFIDENCE_THRESHOLD = 60\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            for (x, y_, w, h) in faces:\n",
        "                X.append(cv2.resize(img[y_:y_ + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id)\n",
        "    if not X: raise ValueError(\"No faces detected.\")\n",
        "    return np.array(X, np.uint8), np.array(y, np.int32), labels\n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.FisherFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return print(\"Camera error.\")\n",
        "    print(\"Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            text = labels.get(label, \"Unknown\") if conf < CONFIDENCE_THRESHOLD else \"Unknown\"\n",
        "            cv2.putText(img, f\"{text}, {conf:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        model, labels = train_model()\n",
        "        recognize_faces(model, labels)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading images and training...\n",
            "Model saved as 'lbph_face_model.yml', Labels saved as 'label_dictionary.npy' {0: 'dad', 1: 'john'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "DATASET_PATH, LBPH_MODEL_PATH, LABEL_DICT_PATH = \"faceset/\", \"lbph_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, label_dict = [], [], {}\n",
        "    for label_id, subdirname in enumerate(sorted(os.listdir(path))):\n",
        "        subject_path = os.path.join(path, subdirname)\n",
        "        if not os.path.isdir(subject_path): continue\n",
        "        label_dict[label_id] = subdirname  \n",
        "        for filename in sorted(os.listdir(subject_path)):\n",
        "            img = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            img = cv2.equalizeHist(img)\n",
        "            faces = face_cascade.detectMultiScale(img, 1.2, 6, minSize=(40, 40))\n",
        "            if len(faces) == 0: continue\n",
        "            X.append(cv2.resize(img[faces[0][1]:faces[0][1] + faces[0][3], faces[0][0]:faces[0][0] + faces[0][2]], IMAGE_SIZE))\n",
        "            y.append(label_id)\n",
        "    return np.array(X, np.uint8), np.array(y, np.int32), label_dict\n",
        "\n",
        "print(\"Reading images and training...\")\n",
        "X, y, label_dict = read_images(DATASET_PATH)\n",
        "if X.size == 0: exit(\"Error: No faces found.\")\n",
        "\n",
        "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "recognizer.train(X, y)\n",
        "recognizer.save(LBPH_MODEL_PATH)\n",
        "np.save(LABEL_DICT_PATH, label_dict)\n",
        "print(f\"Model saved as '{LBPH_MODEL_PATH}', Labels saved as '{LABEL_DICT_PATH}'\", label_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 'q' to quit.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"lbph_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE = (200, 200)\n",
        "CONFIDENCE_THRESHOLD = 100\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            for (x, y_, w, h) in faces:\n",
        "                X.append(cv2.resize(img[y_:y_ + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id)\n",
        "    if not X: raise ValueError(\"No faces detected.\")\n",
        "    return np.array(X, np.uint8), np.array(y, np.int32), labels\n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.LBPHFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return print(\"Camera error.\")\n",
        "    print(\"Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            text = labels.get(label, \"Unknown\") if conf < CONFIDENCE_THRESHOLD else \"Unknown\"\n",
        "            cv2.putText(img, f\"{text}, {conf:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        model, labels = train_model()\n",
        "        recognize_faces(model, labels)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb6Zeh9S5Y1o"
      },
      "source": [
        "**Question: The `predict()` method returns a two-element array. Provide your analysis of the two returned values and their important ince this application.**\n",
        "\n",
        "The predict() method returns a predicted label (identity) and a confidence score, which measures the match quality. In LBPH, a lower confidence score indicates a better match, whereas higher scores suggest uncertainty. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgo4nuQt506X"
      },
      "source": [
        "Your accomplisment of the tasks below contribute to the achievement of ILO1, ILO2, and ILO3 for this module.\n",
        "\n",
        "---\n",
        "\n",
        "Tasks:\n",
        "1. Create a new dataset for testing, this dataset must include the following:\n",
        "  - The same person/s that the model has to recognize.\n",
        "  - Different person/s that the model should not recognize.\n",
        "2. For each model, perform 20 tests. Document the testing performed and provide observations.\n",
        "3. Conclude on the performed tests by providing your evaluation of the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"eigen_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE, ALLOWED_PERSON, CONFIDENCE_THRESHOLD = (200, 200), \"john\", 5000 \n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}  # Ensure y is a list\n",
        "\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "\n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            \n",
        "            for (x, y_pos, w, h) in faces:  \n",
        "                X.append(cv2.resize(img[y_pos:y_pos + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id) \n",
        "\n",
        "    if not X:\n",
        "        raise ValueError(\"No faces detected.\")\n",
        "\n",
        "    return np.array(X, dtype=np.uint8), np.array(y, dtype=np.int32), labels  \n",
        "\n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.EigenFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return\n",
        "\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            name = labels.get(label, \"Unknown\")\n",
        "\n",
        "            if name == ALLOWED_PERSON and conf < CONFIDENCE_THRESHOLD:\n",
        "                box_color, text_color, status = (0, 255, 0), (0, 255, 0), \"RECOGNIZE FACE\"\n",
        "            else:\n",
        "                name, box_color, text_color, status = \"Unknown\", (0, 0, 255), (0, 0, 255), \"UNKNOWN FACE\"\n",
        "\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), box_color, 3)\n",
        "            cv2.putText(img, status, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, \"MODEL USED: EIGENFACES\", (x, y - 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            \n",
        "            if name != \"Unknown\":\n",
        "                cv2.putText(img, f\"NAME: {name}\", (x + w + 15, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "                cv2.putText(img, f\"ID: {label}\", (x + w + 15, y + 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "            cv2.putText(img, \"CONFIDENCE LVL:\", (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, f\"{conf:.2f}\", (x + 180, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, labels = train_model()\n",
        "    recognize_faces(model, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"lbph_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE, ALLOWED_PERSON, CONFIDENCE_THRESHOLD = (200, 200), \"john\", 60\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}\n",
        "\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "\n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            \n",
        "            for (x, y_pos, w, h) in faces:\n",
        "                X.append(cv2.resize(img[y_pos:y_pos + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id)\n",
        "\n",
        "    if not X:\n",
        "        raise ValueError(\"No faces detected.\")\n",
        "\n",
        "    return np.array(X, dtype=np.uint8), np.array(y, dtype=np.int32), labels  \n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.LBPHFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return\n",
        "\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            name = labels.get(label, \"Unknown\")\n",
        "\n",
        "            if name == ALLOWED_PERSON and conf < CONFIDENCE_THRESHOLD:\n",
        "                box_color, text_color, status = (0, 255, 0), (0, 255, 0), \"RECOGNIZE FACE\"\n",
        "            else:\n",
        "                name, box_color, text_color, status = \"Unknown\", (0, 0, 255), (0, 0, 255), \"UNKNOWN FACE\"\n",
        "\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), box_color, 3)\n",
        "            cv2.putText(img, status, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, \"MODEL USED: LBPH\", (x, y - 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            \n",
        "            if name != \"Unknown\":\n",
        "                cv2.putText(img, f\"NAME: {name}\", (x + w + 15, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "                cv2.putText(img, f\"ID: {label}\", (x + w + 15, y + 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "            cv2.putText(img, \"CONFIDENCE LVL:\", (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, f\"{conf:.2f}\", (x + 180, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, labels = train_model()\n",
        "    recognize_faces(model, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "DATASET_PATH, MODEL_PATH, LABEL_PATH = \"faceset/\", \"fisher_face_model.yml\", \"label_dictionary.npy\"\n",
        "IMAGE_SIZE, ALLOWED_PERSON, CONFIDENCE_THRESHOLD = (200, 200), \"john\", 300\n",
        "\n",
        "\n",
        "def read_images(path):\n",
        "    X, y, labels = [], [], {}\n",
        "\n",
        "    for label_id, subdir in enumerate(sorted(os.listdir(path))):\n",
        "        subpath = os.path.join(path, subdir)\n",
        "        if not os.path.isdir(subpath): continue\n",
        "        labels[label_id] = subdir  \n",
        "\n",
        "        for file in sorted(os.listdir(subpath)):\n",
        "            img = cv2.imread(os.path.join(subpath, file), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None: continue\n",
        "            faces = face_cascade.detectMultiScale(cv2.equalizeHist(img), 1.2, 6, minSize=(40, 40))\n",
        "            \n",
        "            for (x, y_pos, w, h) in faces:\n",
        "                X.append(cv2.resize(img[y_pos:y_pos + h, x:x + w], IMAGE_SIZE))\n",
        "                y.append(label_id)\n",
        "\n",
        "    if not X:\n",
        "        raise ValueError(\"No faces detected.\")\n",
        "\n",
        "    return np.array(X, dtype=np.uint8), np.array(y, dtype=np.int32), labels  \n",
        "\n",
        "def train_model():\n",
        "    X, y, labels = read_images(DATASET_PATH)\n",
        "    model = cv2.face.FisherFaceRecognizer_create()\n",
        "    model.train(X, y)\n",
        "    model.save(MODEL_PATH)\n",
        "    np.save(LABEL_PATH, labels)\n",
        "    return model, labels\n",
        "\n",
        "def recognize_faces(model, labels):\n",
        "    cam = cv2.VideoCapture(0)\n",
        "    if not cam.isOpened(): return\n",
        "\n",
        "    while True:\n",
        "        ret, img = cam.read()\n",
        "        if not ret: break\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.2, 6, minSize=(50, 50))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            roi = cv2.resize(gray[y:y + h, x:x + w], IMAGE_SIZE)\n",
        "            label, conf = model.predict(roi)\n",
        "            name = labels.get(label, \"Unknown\")\n",
        "\n",
        "            if name == ALLOWED_PERSON and conf < CONFIDENCE_THRESHOLD:\n",
        "                box_color, text_color, status = (0, 255, 0), (0, 255, 0), \"RECOGNIZE FACE\"\n",
        "            else:\n",
        "                name, box_color, text_color, status = \"Unknown\", (0, 0, 255), (0, 0, 255), \"UNKNOWN FACE\"\n",
        "\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), box_color, 3)\n",
        "            cv2.putText(img, status, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, \"MODEL USED: FISHERFACES\", (x, y - 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            \n",
        "            if name != \"Unknown\":\n",
        "                cv2.putText(img, f\"NAME: {name}\", (x + w + 15, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "                cv2.putText(img, f\"ID: {label}\", (x + w + 15, y + 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "            cv2.putText(img, \"CONFIDENCE LVL:\", (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "            cv2.putText(img, f\"{conf:.2f}\", (x + 180, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
        "\n",
        "        cv2.imshow(\"Face Recognition\", img)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
        "\n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, labels = train_model()\n",
        "    recognize_faces(model, labels)\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "### **Summary**\n",
        "This exercise entailed the application of face recognition with different algorithms on a dataset created by oneself. It focused on data preparation, training, and evaluation of the model, with special emphasis on how preprocessing affects accuracy.\n",
        "\n",
        "### **Conclusions**\n",
        "I effectively implemented face recognition algorithms and saw how various algorithms react to lighting and angle changes. Results highlighted the significance of robust preprocessing and data quality in reducing errors.\n",
        "\n",
        "### **Lessons Learned**\n",
        "Effective data preparation is important for accuracy since bad input impacts performance. Various algorithms produce bad results, and environmental conditions such as lighting influence recognition. Analysis of multiple models is important for choosing the optimum approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw",
        "X-RNZovNGV9k",
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
